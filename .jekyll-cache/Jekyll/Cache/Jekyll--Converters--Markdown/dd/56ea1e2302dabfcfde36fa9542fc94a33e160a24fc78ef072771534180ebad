I"S<<p>First of all you need to install Deep Learning Studio. If you haven’t completed that step, please go to the <a href="/install/">installation section</a>.</p>

<p>We additionally have some implemented algorithms that you can use in Deep Learning Studio. Find them in the <a href="/quick_start/algorithms_zoo/">algorithms zoo</a>.</p>

<p>If you’d like to train your own brain, we provide you with the <a href="/quick_start/datasets">datasets</a>.</p>

<p>This repository contains the deep learning regression and classification models for all robots used in the JdeRobot community.</p>

<h2 id="structure-of-the-branch">Structure of the branch</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>├── Formula1-FollowLine
|   |
|   |── pytorch
|   |   |── PilotNet                                # Pilot Net pytorch implementation
|   |   |   ├── scripts                             # scripts for running experiments 
|   |   |   ├── utils                               
|   |   |   |   ├── pilot_net_dataset.py            # Torchvision custom dataset
|   |   |   |   ├── pilotnet.py                     # CNN for PilotNet
|   |   |   |   ├── transform_helpers.py            # Data Augmentation
|   |   |   |   └── processing.py                   # Data collecting, processing and utilities
|   |   |   └── train.py                            # training code
|   |   |
|   |   └── PilotNetStacked                         # Pilot Net Stacked Image implementation
|   |       ├── scripts                             # scripts for running experiments 
|   |       ├── utils                               
|   |       |   ├── pilot_net_dataset.py            # Sequentially stacked image dataset
|   |       |   ├── pilotnet.py                     # Modified Hyperparams 
|   |       |   ├── transform_helpers.py            # Data Augmentation
|   |       |   └── processing.py                   # Data collecting, processing and utilities
|   |       └── train.py                            # training code
|   |
|   +── tensoflow
|       +── PilotNet                                # Pilot Net tensorflow implementation
|           ├── utils                               
|           |   ├── dataset.py                      # Custom dataset
|           |   ├── pilotnet.py                     # CNN for PilotNet
|           |   └── processing.py                   # Data collecting, processing and utilities
|           └── train.py                            # training code
+── Drone-FollowLine
    |
    +── DeepPilot                               # DeepPilot CNN pytorch implementation
        ├── scripts                             # scripts for running experiments 
        ├── utils                               
        |   ├── pilot_net_dataset.py            # Torchvision custom dataset
        |   ├── pilotnet.py                     # CNN for DeepPilot
        |   ├── transform_helpers.py            # Data Augmentation
        |   └── processing.py                   # Data collecting, processing and utilities
        └── train.py                            # training code
</code></pre></div></div>

<h1 id="formula1-followline-algorithms-implementation-and-baseline">Formula1 Followline Algorithms: Implementation and Baseline</h1>

<p>It contains some deep learning regression models for Formula1 Line Following task.</p>

<p>The models implemented are derived from:</p>
<ol>
  <li>PilotNet for Autonomous Driving with Behaviour Metrics dataset</li>
  <li>PilotNetStacked as an extension of PilotNet with stacked images</li>
</ol>

<p>The algorithms are modular and can adapt to various other datasets. They are both implemented in pytorch and tensorflow.</p>

<h1 id="pytorch-">Pytorch <img src="https://pytorch.org/assets/images/pytorch-logo.png" alt="Pytorch logo" width="50" /></h1>

<h2 id="preparing-dataset">Preparing Dataset</h2>

<p>For PilotNet, we use our custom datasets:</p>
<ul>
  <li>Complete dataset: contains images with annotations from different circuits <a href="https://drive.google.com/file/d/1Xdiu69DLj7lKK37F94qrUWsXkVg4ymGv/view?usp=sharing">https://drive.google.com/file/d/1Xdiu69DLj7lKK37F94qrUWsXkVg4ymGv/view?usp=sharing</a></li>
  <li>Curves dataset: contains images with annotations from many_curves circuit: <a href="https://drive.google.com/file/d/1zCJPFJRqCa34Q6jvktjDBY8Z49bIbvLJ/view?usp=sharing">https://drive.google.com/file/d/1zCJPFJRqCa34Q6jvktjDBY8Z49bIbvLJ/view?usp=sharing</a></li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    PilotNet                                # Extract PilotNet dataset here
    ├── complete_dataset                    # Extract PilotNet complete_dataset here           
    |   ├── Images/                         # Train and Test Images
    |   └── data.json                       # Annotations
    └── curves_dataset                      # Extract PilotNet curves_dataset here  
        ├── Images/                         # Train and Test Images
        └── data.json                       # Annotations
</code></pre></div></div>

<h2 id="hyperparameters-for-the-code">Hyperparameters for the code</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># For PilotNet

-h, --help                            show this help message and exit
--data_dir            DATA_DIR        Directory to find Data
--preprocess	      PREPROCESSING   Preprocessing information about cropping and extreme cases 
--base_dir            BASE_DIR        Directory to save everything
--comment             COMMENT         Comment to know the experiment
--data_augs           AUGMENTATIONS   Data augmentations
--num_epochs          NUM_EPOCHS      Number of Epochs
--lr                  LR              Learning rate for Policy Net
--test_split          TEST_SPLIT      Train test Split
--shuffle             SHUFFLE         Shuffle dataset
--batch_size          BATCH_SIZE      Batch size
--save_iter           SAVE_ITER       Iterations to save the model
--print_terminal      PRINT_TERMINAL  Print progress in terminal
--seed                SEED            Seed for reproducing

# For PilotNetStacked, add

--horizon             HORIZON         Stacking horizon to use

</code></pre></div></div>

<h2 id="running-the-code">Running the Code</h2>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">source</span> ~/pyenvs/dlstudio/bin/activate
<span class="nb">cd </span>DeepLearningStudio/Formula1-FollowLine/pytorch

<span class="c"># For PilotNet</span>

<span class="nb">cd </span>PilotNet
python train.py <span class="nt">--data_dir</span> <span class="s1">'../datasets/complete_dataset'</span> <span class="se">\</span>
	    <span class="nt">--data_dir</span> <span class="s1">'../datasets/curves_only'</span> <span class="se">\</span>
		<span class="nt">--preprocess</span> <span class="s1">'crop'</span> <span class="se">\</span>
		<span class="nt">--preprocess</span> <span class="s1">'extreme'</span> <span class="se">\</span>
	    <span class="nt">--base_dir</span> testcase <span class="se">\</span>
	    <span class="nt">--comment</span> <span class="s1">'Selected Augmentations: gaussian, affine'</span> <span class="se">\</span>
	    <span class="nt">--data_augs</span> <span class="s1">'gaussian'</span> <span class="se">\</span>
	    <span class="nt">--data_augs</span> <span class="s1">'affine'</span> <span class="se">\</span>
	    <span class="nt">--num_epochs</span> 150 <span class="se">\</span>
	    <span class="nt">--lr</span> 1e-3 <span class="se">\</span>
	    <span class="nt">--test_split</span> 0.2 <span class="se">\</span>
	    <span class="nt">--shuffle</span> True <span class="se">\</span>
	    <span class="nt">--batch_size</span> 128 <span class="se">\</span>
	    <span class="nt">--save_iter</span> 50 <span class="se">\</span>
	    <span class="nt">--print_terminal</span> True <span class="se">\</span>
	    <span class="nt">--seed</span> 123  

<span class="c"># For PilotNetStacked</span>

<span class="nb">cd </span>PilotNetStacked
python train.py <span class="nt">--data_dir</span> <span class="s1">'../datasets/complete_dataset'</span> <span class="se">\</span>
		<span class="nt">--data_dir</span> <span class="s1">'../datasets/curves_only'</span> <span class="se">\</span>
		<span class="nt">--preprocess</span> <span class="s1">'crop'</span> <span class="se">\</span>
		<span class="nt">--preprocess</span> <span class="s1">'extreme'</span> <span class="se">\</span>
		<span class="nt">--base_dir</span> testcase <span class="se">\</span>
		<span class="nt">--comment</span> <span class="s1">'Selected Augmentations: gaussian'</span> <span class="se">\</span>
		<span class="nt">--data_augs</span> <span class="s1">'gaussian'</span> <span class="se">\</span>
		<span class="nt">--num_epochs</span> 150 <span class="se">\</span>
		<span class="nt">--horizon</span> 3 <span class="se">\</span>
		<span class="nt">--lr</span> 1e-3 <span class="se">\</span>
		<span class="nt">--test_split</span> 0.2 <span class="se">\</span>
		<span class="nt">--shuffle</span> True <span class="se">\</span>
		<span class="nt">--batch_size</span> 256 <span class="se">\</span>
		<span class="nt">--save_iter</span> 50 <span class="se">\</span>
		<span class="nt">--print_terminal</span> True <span class="se">\</span>
		<span class="nt">--seed</span> 123
</code></pre></div></div>

<p>The results are saved in the <code class="language-plaintext highlighter-rouge">./experiments/</code> directory and the structure is given below. 
Tensorboard can be launched with <code class="language-plaintext highlighter-rouge">./experiments/base_dir/log</code> directory.</p>

<h1 id="tensorflow-">Tensorflow <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/2d/Tensorflow_logo.svg/1200px-Tensorflow_logo.svg.png" alt="TF logo" width="50" /></h1>

<p>The models implemented are derived from:</p>
<ol>
  <li>PilotNet for Autonomous Driving with Behaviour Metrics dataset</li>
  <li>DeepestLSTMTinyPilotNet as an extension of PilotNet with ConvLSTM layers.</li>
</ol>

<h2 id="preparing-dataset-1">Preparing Dataset</h2>

<p>The same workflow as for PyTorch is followed, refer to the previous section</p>

<h2 id="hyperparameters-for-the-code-1">Hyperparameters for the code</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># For PilotNet or DeepestLSTMTinyPilotNet

-h, --help                            show this help message and exit
--data_dir            DATA_DIR        Directory to find Data
--preprocess          PREPROCESSING   Preprocessing information about cropping and extreme cases 
--data_augs           AUGMENTATIONS   Data augmentations
--num_epochs          NUM_EPOCHS      Number of Epochs
--learning_rate       LR              Learning rate for Policy Net
--batch_size          BATCH_SIZE      Batch size
--img_shape	      IMG_SHAPE	      Image shape


</code></pre></div></div>

<h2 id="running-the-code-1">Running the Code</h2>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">source</span> ~/pyenvs/dlstudio/bin/activate
<span class="nb">cd </span>DeepLearningStudio/Formula1-FollowLine/tensorflow

<span class="c"># For PilotNet</span>

<span class="nb">cd </span>PilotNet
python train.py <span class="nt">--data_dir</span> ../complete_dataset/ <span class="se">\</span>
	<span class="nt">--preprocess</span> crop <span class="se">\</span>
	<span class="nt">--preprocess</span> extreme <span class="se">\</span>
	<span class="nt">--data_augs</span> True <span class="se">\</span>
	<span class="nt">--num_epochs</span> 1 <span class="se">\</span>
	<span class="nt">--batch_size</span> 50 <span class="se">\</span>
	<span class="nt">--learning_rate</span> 0.0001 <span class="se">\</span>
	<span class="nt">--img_shape</span> <span class="s2">"200,66,3"</span>
	
	
<span class="c"># For DeepestLSTMTinyPilotNet</span>
python train.py <span class="nt">--data_dir</span> ../complete_dataset/ <span class="se">\</span>
	<span class="nt">--preprocess</span> crop <span class="se">\</span>
	<span class="nt">--preprocess</span> extreme <span class="se">\</span>
	<span class="nt">--data_augs</span> True <span class="se">\</span>
	<span class="nt">--num_epochs</span> 1 <span class="se">\</span>
	<span class="nt">--batch_size</span> 50 <span class="se">\</span>
	<span class="nt">--learning_rate</span> 0.0001 <span class="se">\</span>
	<span class="nt">--img_shape</span> <span class="s2">"100,50,3"</span>

</code></pre></div></div>

<p>The results are saved in  <code class="language-plaintext highlighter-rouge">./</code> directory and the structure is given below. 
Tensorboard can be launched with <code class="language-plaintext highlighter-rouge">logs/fit</code> directory.</p>

<h3 id="building-your-configuration-file">Building your configuration file</h3>

<p>If you want to create your own <strong>configuration file</strong> for the application (changing the robot, brain, layout, etc) you can either use the desktop GUI or creating a yml file with your own configuration. The default profile looks like this (<strong>Make sure you respect the indentation</strong>):</p>

<h2 id="references">References</h2>

<ol>
  <li>Bojarski, Mariusz, Davide Del Testa, Daniel Dworakowski, Bernhard Firner, Beat Flepp, Prasoon Goyal, Lawrence D. Jackel et al. “End to end learning for self-driving cars.” arXiv preprint arXiv:1604.07316 (2016). <a href="https://arxiv.org/abs/1604.07316">https://arxiv.org/abs/1604.07316</a></li>
</ol>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@article{bojarski2016end,
  title={End to end learning for self-driving cars},
  author={Bojarski, Mariusz and Del Testa, Davide and Dworakowski, Daniel and Firner, Bernhard and Flepp, Beat and Goyal, Prasoon and Jackel, Lawrence D and Monfort, Mathew and Muller, Urs and Zhang, Jiakai and others},
  journal={arXiv preprint arXiv:1604.07316},
  year={2016}
}

@article{bojarski2017explaining,
  title={Explaining how a deep neural network trained with end-to-end learning steers a car},
  author={Bojarski, Mariusz and Yeres, Philip and Choromanska, Anna and Choromanski, Krzysztof and Firner, Bernhard and Jackel, Lawrence and Muller, Urs},
  journal={arXiv preprint arXiv:1704.07911},
  year={2017}
}
</code></pre></div></div>

<ol>
  <li>Rojas-Perez, L.O., &amp; Martinez-Carranza, J. (2020). DeepPilot: A CNN for Autonomous Drone Racing. Sensors, 20(16), 4524. <a href="https://doi.org/10.3390/s20164524">https://doi.org/10.3390/s20164524</a></li>
</ol>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@article{rojas2020deeppilot,
  title={DeepPilot: A CNN for Autonomous Drone Racing},
  author={Rojas-Perez, Leticia Oyuki and Martinez-Carranza, Jose},
  journal={Sensors},
  volume={20},
  number={16},
  pages={4524},
  year={2020},
  publisher={Multidisciplinary Digital Publishing Institute}
}
</code></pre></div></div>
:ET